{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import kdtree\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "from tests.read_test_map import read_test_map\n",
    "from visualization.map_visualization import show_map_vectorized\n",
    "from visualization.rrt_visualization import visualize_rrt\n",
    "from tests.check_results import construct_path_from_node\n",
    "from utils.node import RRTNode\n",
    "from shapely.geometry import Polygon as ShapelyPolygon, Point, LineString\n",
    "from typing import List, Tuple, Union, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./media/tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling-Based алгоритм RRT для задачи поиска пути\n",
    "В данной лабораторной работе мы изучим задачу поиска пути в непрерывном пространстве для агента-робота, используя подход на основе сэмплирования. Основной метод, который мы будем рассматривать, — это алгоритм Rapidly-exploring Random Tree (RRT), широко применяемый для планирования траекторий в сложных конфигурационных пространствах.\n",
    "\n",
    "Алгоритм RRT опирается на построение специальной структуры данных — дерева, которое быстро охватывает область поиска за счет последовательного добавления новых узлов. Каждый узел дерева, за исключением корня, имеет ровно одного родителя. На каждом шаге алгоритм генерирует новый узел и пытается присоединить его к существующему дереву. Конечная цель заключается в том, чтобы достичь области, близкой к целевой точке, посредством последовательного расширения дерева.\n",
    "\n",
    "Процесс расширения дерева RRT можно описать следующим образом:\n",
    "\n",
    "1) **Генерация случайной точки:** выбрать случайную точку x<sub>rand</sub> пространстве.  \n",
    "2) **Поиск ближайшего узла:** найти узел x<sub>near</sub> в текущем дереве, ближайший к точке x<sub>rand</sub> \n",
    "3) **Расширение дерева:** создать новый узел x<sub>new</sub> в направлении от точки x<sub>near</sub> к x<sub>rand</sub>.  \n",
    "\n",
    "Преимущество алгоритмов RRT и других методов на основе сэмплинга заключается в их применимости для задач поиска пути в непрерывных пространствах с учетом различных ограничений — геометрических (например, форма и размеры агента) и кинематических (ограничения на скорость и ускорение). Эти методы особенно эффективны при решении задач высокой размерности, таких как планирование движений манипуляторов.\n",
    "\n",
    "Однако в данной лабораторной работе мы сосредоточимся на ключевых идеях алгоритмов на основе сэмплинга, применяя их к задаче поиска пути на двумерной плоскости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Представление пространства\n",
    "\n",
    "Для моделирования задачи поиска пути и построения дерева RRT в этой лабораторной работе используется двумерное пространство, в котором могут находиться препятствия, заданные в виде многоугольников.\n",
    "\n",
    "## Описание препятствий\n",
    "\n",
    "Препятствия определяются как наборы вершин многоугольников. Каждое препятствие представлено списком координат вершин в формате *(x, y)*. Например, список `obstacles_sample` содержит два препятствия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obstacles_sample = [[(2, 2), (3, 3), (2, 4), (1, 3)],\n",
    "             [(5, 5), (6, 7), (7, 6)],\n",
    "             ]\n",
    "\n",
    "show_map_vectorized(10, 10, obstacles_sample, show_cords=False, show_obstacles_index=True, show_vertexes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## RRTNode и KDTree\n",
    "Алгоритм RRT строит дерево поиска, сэмплируя новые состояния и пытаясь соединить их с уже существующими узлами дерева. Одной из ключевых операций в процессе работы алгоритма является поиск ближайшего узла дерева к новому, только что сэмплированному состоянию. Эта операция будет выполняться многократно и желательно реализовать её эффективно.\n",
    "\n",
    "Для реализации данной задачи мы будем использовать внешний модуль `kdtree`, который предоставляет структуру данных — [k-d-дерево](https://ru.wikipedia.org/wiki/K-d-дерево). K-d-дерево позволяет эффективно выполнять операции добавления элементов и поиска ближайших соседей с хорошей асимптотикой:\n",
    "\n",
    "* Добавление элемента: **O(h)**  \n",
    "* Поиск ближайшего соседа: **O(h) * (O(log(h)) + 1)**    \n",
    "\n",
    "Где h — это высота дерева.\n",
    "### Структура узлов дерева — RRTNode\n",
    "Для заполнения дерева мы будем использовать объекты типа `RRTNode`. Каждый такой объект представляет собой узел дерева поиска, который хранит в себе следующую информацию:\n",
    "* Координаты точки в пространстве (поле `state`)\n",
    "* Ссылку на родительский узел (поле `parent`)\n",
    "* Длина пути от корневого узла до текущего (поле `g`)\n",
    "\n",
    "### Пример работы с RRTNode и KDTree\n",
    "Для начала создадим корень дерева `RRTNode`, представляющий начальное состояние:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_node = RRTNode(state=(0, 0), parent=None, g=0)  # Создание корня дерева\n",
    "tree = kdtree.create([root_node])  # Создание дерева KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем добавим в дерево несколько новых узлов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cords = [(0, 1), (1, 2), (3, 5), (4, 2)]  # Набор координат новых узлов\n",
    "for cord in cords:\n",
    "    tree.add(RRTNode(state=cord, parent=root_node))  # Добавление новых вершин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно найти ближайший узел к произвольной точке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ближайший узел: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "state_query = (2, 3)  # Состояние, для которого ищем ближайший узел\n",
    "nearest_node = tree.search_nn(state_query)[0].data  # Поиск ближайшего узла\n",
    "print(\"Ближайший узел:\", nearest_node.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_collision(state: Tuple[float, float], obstacles) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, есть ли пересечение между заданным состоянием и препятствиями.\n",
    "\n",
    "    Args:\n",
    "        state: Координаты состояния (x, y).\n",
    "        obstacles: Список препятствий.\n",
    "\n",
    "    Return:\n",
    "        bool: True, если состояние пересекается с каким-либо препятствием, иначе False.\n",
    "    \"\"\"\n",
    "    for obs in obstacles:\n",
    "        if ShapelyPolygon(obs).contains(Point(state)):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def distance(state1: Tuple[float, float], state2: Tuple[float, float]) -> float:\n",
    "    \"\"\"\n",
    "    Вычисляет расстояние между двумя состояниями в пространстве.\n",
    "\n",
    "    В данной лабораторной работе используется евклидово расстояние между точками на плоскости.\n",
    "\n",
    "    Args:\n",
    "        state1: Координаты первого состояния.\n",
    "        state2: Координаты второго состояния.\n",
    "\n",
    "    Return:\n",
    "        float: Евклидово расстояние между двумя состояниями.\n",
    "    \"\"\"\n",
    "    return Point(state1).distance(Point(state2))\n",
    "\n",
    "\n",
    "def in_goal_region(state: Tuple[float, float], state_goal: Tuple[float, float], region_size: float) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, находится ли заданное состояние в пределах допустимого расстояния от целевого состояния.\n",
    "\n",
    "    Args:\n",
    "        state: Координаты проверяемого состояния.\n",
    "        state_goal: Координаты целевого состояния.\n",
    "        region_size: Радиус области, в пределах которой состояние считается достижением цели.\n",
    "\n",
    "    Return:\n",
    "        bool: True, если состояние находится в пределах области цели, иначе False.\n",
    "    \"\"\"\n",
    "    return distance(state, state_goal) <= region_size\n",
    "    \n",
    "\n",
    "def is_trajectory_clear(start_state: Tuple[float, float], end_state: Tuple[float, float], obstacles: List[ShapelyPolygon]) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, пересекает ли траектория, задаваемая начальным и конечным состояниями, какие-либо препятствия.\n",
    "\n",
    "    Args:\n",
    "        start_state: Координаты начального состояния.\n",
    "        end_state: Координаты конечного состояния.\n",
    "        obstacles: Список препятствий.\n",
    "\n",
    "    Return:\n",
    "        bool: True, если траектория свободна от пересечений, иначе False.\n",
    "    \"\"\"\n",
    "    for obs in obstacles:\n",
    "        if LineString([start_state, end_state]).intersects(ShapelyPolygon(obs)):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def create_random_state(map_width: float, map_height: float, \n",
    "                        goal_bias: float, goal_state: Tuple[float, float], \n",
    "                        goal_sampling_region: float) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Генерирует случайное состояние в пространстве поиска.\n",
    "\n",
    "    С вероятностью `goal_bias` возвращает состояние в окрестности цели в пределах размера области `goal_sampling_region` \n",
    "    (любое, можно саму цель всегда возвращать). \n",
    "    В противном случае генерирует равномерно случайное состояние в пределах карты.\n",
    "\n",
    "    Args:\n",
    "        map_width: Ширина карты.\n",
    "        map_height: Высота карты.\n",
    "        goal_bias: Вероятность генерации состояния около цели.\n",
    "        goal_state: Координаты целевого состояния.\n",
    "        goal_sampling_region: Размер области около цели.\n",
    "\n",
    "    Return:\n",
    "        tuple[float, float]: Случайное состояние (x, y).\n",
    "    \"\"\"\n",
    "    if random.random() < goal_bias:\n",
    "        return goal_state\n",
    "    else:\n",
    "        return (random.uniform(0, map_width), random.uniform(0, map_height))\n",
    "\n",
    "\n",
    "def find_nearest_neighbour(tree: kdtree, state_random: Tuple[float, float]) -> RRTNode:\n",
    "    \"\"\"\n",
    "    Находит ближайший узел в дереве поиска к заданному случайному состоянию.\n",
    "\n",
    "    Args:\n",
    "        tree: KD-дерево, представляющее текущее дерево поиска.\n",
    "        state_random: Случайно сгенерированное состояние.\n",
    "\n",
    "    Return:\n",
    "        RRTNode: Ближайший узел в дереве к заданному состоянию.\n",
    "    \"\"\"\n",
    "    return tree.search_nn(state_random)[0].data\n",
    "\n",
    "\n",
    "def extend(tree: kdtree, obstacles: List[ShapelyPolygon], \n",
    "           state_random: Tuple[float, float], \n",
    "           max_transition: float) -> Tuple[bool, Optional[RRTNode]]:\n",
    "    \"\"\"\n",
    "    Расширяет дерево поиска, пытаясь создать новое состояние в направлении заданного случайного состояния\n",
    "    (проверяется точка, находящаяся на расстоянии минимума из расстояния до ближайшего соседа и `max_transition`).\n",
    "\n",
    "    Если новое состояние валидно и не пересекается с препятствиями, оно добавляется в дерево.\n",
    "\n",
    "    Args:\n",
    "        tree: KD-дерево, представляющее текущее дерево поиска.\n",
    "        obstacles: Список препятствий в пространстве.\n",
    "        state_random: Случайно сгенерированное состояние.\n",
    "        max_transition: Максимально допустимое расстояние перехода.\n",
    "\n",
    "    Return:\n",
    "        tuple[bool, Optional[RRTNode]]: \n",
    "            - Флаг успешного добавления нового состояния.\n",
    "            - Новый узел, если состояние было добавлено, иначе None.\n",
    "\n",
    "    ! Не забудьте при составлении RRTNode указать его родителя и стоимость перехода в него\n",
    "    \"\"\"\n",
    "    nearest_node = find_nearest_neighbour(tree, state_random)\n",
    "    distance_to_nearest = distance(state_random, nearest_node.state)\n",
    "    if distance_to_nearest < max_transition:\n",
    "        new_state = nearest_node.state\n",
    "    else:\n",
    "        new_state = (nearest_node.state[0] + max_transition * (state_random[0] - nearest_node.state[0]) / distance_to_nearest,\n",
    "                     nearest_node.state[1] + max_transition * (state_random[1] - nearest_node.state[1]) / distance_to_nearest)\n",
    "    if not in_collision(new_state, obstacles):\n",
    "        new_node = RRTNode(state=new_state, parent=nearest_node, g=nearest_node.g + distance_to_nearest)\n",
    "        return True, new_node\n",
    "    else:\n",
    "        return False, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основной алгоритм RRT\n",
    "\n",
    "Функция `rrt` собирает вместе весь функционал алгоритма поиска пути. На каждом шаге алгоритм выполняет следующие действия:\n",
    "\n",
    "1. Генерирует случайное состояние с помощью `create_random_state`.\n",
    "\n",
    "2. Расширяет дерево с помощью функции `extend`. \n",
    "\n",
    "3. Проверяет, достиг ли алгоритм целевой области.\n",
    "\n",
    "Если цель достигнута или превышено максимальное количество итераций, функция завершает свою работу.\n",
    "\n",
    "\n",
    "Обратите внимание! Сохраняйте все добавленные узлы в список `all_points`, чтобы впоследствии визуализировать процесс построения дерева.\n",
    "Также не забывайте пополнять ими дерево через `tree.add(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrt(map_w: int,\n",
    "        map_h: int,\n",
    "        obstacles: List[List[float]], \n",
    "        start_x: float, \n",
    "        start_y: float, \n",
    "        goal_x: float, \n",
    "        goal_y: float, \n",
    "        max_transition: float,\n",
    "        max_iter: int = 3000, \n",
    "        goal_region: float = 5,\n",
    "        goal_bias: float = 0.05\n",
    "        ) -> Tuple[bool, Optional['RRTNode'], int, Optional['kdtree.KDTree'], List[Tuple['RRTNode', int]]]:\n",
    "    \"\"\"\n",
    "    Реализует алгоритм поиска RRT.\n",
    "\n",
    "    Args:\n",
    "        map_w: Ширина карты.\n",
    "        map_h: Высота карты.\n",
    "        obstacles: Список препятствий на карте.\n",
    "        start_x: Координата x начальной точки.\n",
    "        start_y: Координата y начальной точки.\n",
    "        goal_x: Координата x цели.\n",
    "        goal_y: Координата y цели.\n",
    "        max_transition: Максимальное расстояние, на которое может перемещаться агент за один шаг.\n",
    "        max_iter: Максимальное количество итераций алгоритма.\n",
    "        goal_region: Размер окрестности целевого состояния, в которой цель считается достигнутой.\n",
    "        goal_bias: Вероятность сэмплинга состояния, близкого к цели.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[bool, Optional[RRTNode], int, Optional[kdtree.KDTree], List[RRTNode]]:\n",
    "            - Булевое значение, указывающее, был ли найден путь.\n",
    "            - Последний узел найденного пути или None, если путь не был найден.\n",
    "            - Количество итераций, выполненных алгоритмом.\n",
    "            - KD-дерево, представляющее дерево поиска, или None, если путь не найден.\n",
    "            - Список всех узлов, добавленных в дерево, в порядке добавления, а также итерация на которой узел был добавлен\n",
    "    \"\"\"\n",
    "    \n",
    "    node_start = RRTNode([start_x, start_y], None, 0.0)\n",
    "    state_goal = [goal_x, goal_y]\n",
    "    tree = kdtree.create([node_start])\n",
    "    all_points = [(node_start, 0)] # тут хранятся пары из вершин (RRTNode) и номера итерации на котором их добавили\n",
    "    \n",
    "    for iter in range(1, max_iter + 1):\n",
    "        state_random = create_random_state(map_w, map_h, goal_bias, state_goal, goal_region)\n",
    "        success, new_node = extend(tree, obstacles, state_random, max_transition)\n",
    "        if success:\n",
    "            all_points.append((new_node, iter))\n",
    "            tree.add(new_node)\n",
    "            if in_goal_region(new_node.state, state_goal, goal_region):\n",
    "                return True, new_node, iter, tree, all_points\n",
    "    return False, None, max_iter, tree, all_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./media/maps.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small test\n",
    "Предварительный тест для проверки всё ли у вас правильно работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, start, goal, obstacles = read_test_map(\"./tests/columns_small.txt\")\n",
    "found, end_node, number_of_steps, tree, all_points = rrt(width, height, obstacles, *start, *goal, max_transition=5, goal_bias=0.05, goal_region=5)\n",
    "assert found, \"`found` должно быть True - иначе пробуйте ещё раз или что-то реализовано неверно\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "animation = visualize_rrt(width, height, *start, *goal, obstacles, all_points, construct_path_from_node(end_node), goal_region=5, iterations=number_of_steps, max_iteration=1000, path_length=42)\n",
    "# animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](small_test.png \"Small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, start, goal, obstacles = read_test_map(\"./tests/columns.txt\")\n",
    "found, end_node, number_of_steps, tree, all_points = rrt(width, height, obstacles, *start, *goal, max_transition=7, goal_bias=0.05, goal_region=10)\n",
    "assert found, \"`found` должно быть True - иначе пробуйте ещё раз или что-то реализовано неверно\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "animation = visualize_rrt(width, height, *start, *goal, obstacles, all_points, construct_path_from_node(end_node), goal_region=10, iterations=number_of_steps, max_iteration=10_000, path_length=end_node.g)\n",
    "# animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](columns.png \"Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Obstacles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, start, goal, obstacles = read_test_map(\"./tests/rand_polygons.txt\")\n",
    "found, end_node, number_of_steps, tree, all_points = rrt(width, height, obstacles, *start, *goal, max_transition=7, goal_bias=0.05, goal_region=10)\n",
    "assert found, \"`found` должно быть True - иначе пробуйте ещё раз или что-то реализовано неверно\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "animation = visualize_rrt(width, height, *start, *goal, obstacles, all_points, construct_path_from_node(end_node), goal_region=10, iterations=number_of_steps, max_iteration=10_000, path_length=round(end_node.g,2))\n",
    "# animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](random.png \"Random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massive Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_transitions = [3, 7, 15]\n",
    "goal_regions = [5, 10, 25]\n",
    "goal_biases = [0.05, 0.10, 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.05\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 225, Nodes: 132\n",
      "Avg steps: 177.6\n",
      "Avg nodes: 111.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.1\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 118, Nodes: 76\n",
      "Avg steps: 170\n",
      "Avg nodes: 101.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.15\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 147, Nodes: 84\n",
      "Avg steps: 122.8\n",
      "Avg nodes: 76\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.05\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 60, Nodes: 49\n",
      "Avg steps: 114\n",
      "Avg nodes: 76.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.1\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 216, Nodes: 127\n",
      "Avg steps: 147.6\n",
      "Avg nodes: 92.6\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.15\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 286, Nodes: 149\n",
      "Avg steps: 170\n",
      "Avg nodes: 96.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.05\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 39, Nodes: 25\n",
      "Avg steps: 33.2\n",
      "Avg nodes: 24.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.1\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 17, Nodes: 18\n",
      "Avg steps: 66.8\n",
      "Avg nodes: 39.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.15\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 19, Nodes: 18\n",
      "Avg steps: 40.8\n",
      "Avg nodes: 30.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.05\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 99, Nodes: 51\n",
      "Avg steps: 713.6\n",
      "Avg nodes: 692.6\n",
      "Success rate: 0.80\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.1\n",
      "Goal region: 5\n",
      "First run - Found: False, Steps: 3000, Nodes: 2956\n",
      "Avg steps: 1233.6\n",
      "Avg nodes: 1208.6\n",
      "Success rate: 0.60\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.15\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 38, Nodes: 31\n",
      "Avg steps: 150.6\n",
      "Avg nodes: 133\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.05\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 28, Nodes: 21\n",
      "Avg steps: 33.6\n",
      "Avg nodes: 25.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.1\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 32, Nodes: 30\n",
      "Avg steps: 37.4\n",
      "Avg nodes: 31.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.15\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 13, Nodes: 11\n",
      "Avg steps: 23\n",
      "Avg nodes: 17.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.05\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 6, Nodes: 6\n",
      "Avg steps: 27.4\n",
      "Avg nodes: 18\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.1\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 19, Nodes: 12\n",
      "Avg steps: 19\n",
      "Avg nodes: 12.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.15\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 13, Nodes: 10\n",
      "Avg steps: 18.2\n",
      "Avg nodes: 13.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.05\n",
      "Goal region: 5\n",
      "First run - Found: False, Steps: 3000, Nodes: 2998\n",
      "Avg steps: 2403.4\n",
      "Avg nodes: 2401.6\n",
      "Success rate: 0.20\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.1\n",
      "Goal region: 5\n",
      "First run - Found: False, Steps: 3000, Nodes: 2989\n",
      "Avg steps: 1387.8\n",
      "Avg nodes: 1384\n",
      "Success rate: 0.60\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.15\n",
      "Goal region: 5\n",
      "First run - Found: False, Steps: 3000, Nodes: 2991\n",
      "Avg steps: 3000\n",
      "Avg nodes: 2997.8\n",
      "Success rate: 0.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.05\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 17, Nodes: 16\n",
      "Avg steps: 17.6\n",
      "Avg nodes: 16.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.1\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 9, Nodes: 10\n",
      "Avg steps: 614.2\n",
      "Avg nodes: 611.6\n",
      "Success rate: 0.80\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.15\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 64, Nodes: 62\n",
      "Avg steps: 35\n",
      "Avg nodes: 30.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.05\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 4, Nodes: 5\n",
      "Avg steps: 11.4\n",
      "Avg nodes: 11.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.1\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 12, Nodes: 10\n",
      "Avg steps: 10\n",
      "Avg nodes: 9.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.15\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 4, Nodes: 5\n",
      "Avg steps: 7.2\n",
      "Avg nodes: 6.4\n",
      "Success rate: 1.00\n",
      " max_transition  goal_bias  goal_region  first_run_found  first_run_steps  first_run_nodes  avg_steps  avg_nodes  success_rate\n",
      "              3       0.05            5             True              225              132      177.6      111.2           1.0\n",
      "              3       0.10            5             True              118               76      170.0      101.8           1.0\n",
      "              3       0.15            5             True              147               84      122.8       76.0           1.0\n",
      "              3       0.05           10             True               60               49      114.0       76.4           1.0\n",
      "              3       0.10           10             True              216              127      147.6       92.6           1.0\n",
      "              3       0.15           10             True              286              149      170.0       96.2           1.0\n",
      "              3       0.05           25             True               39               25       33.2       24.2           1.0\n",
      "              3       0.10           25             True               17               18       66.8       39.4           1.0\n",
      "              3       0.15           25             True               19               18       40.8       30.2           1.0\n",
      "              7       0.05            5             True               99               51      713.6      692.6           0.8\n",
      "              7       0.10            5            False             3000             2956     1233.6     1208.6           0.6\n",
      "              7       0.15            5             True               38               31      150.6      133.0           1.0\n",
      "              7       0.05           10             True               28               21       33.6       25.2           1.0\n",
      "              7       0.10           10             True               32               30       37.4       31.2           1.0\n",
      "              7       0.15           10             True               13               11       23.0       17.8           1.0\n",
      "              7       0.05           25             True                6                6       27.4       18.0           1.0\n",
      "              7       0.10           25             True               19               12       19.0       12.8           1.0\n",
      "              7       0.15           25             True               13               10       18.2       13.8           1.0\n",
      "             15       0.05            5            False             3000             2998     2403.4     2401.6           0.2\n",
      "             15       0.10            5            False             3000             2989     1387.8     1384.0           0.6\n",
      "             15       0.15            5            False             3000             2991     3000.0     2997.8           0.0\n",
      "             15       0.05           10             True               17               16       17.6       16.4           1.0\n",
      "             15       0.10           10             True                9               10      614.2      611.6           0.8\n",
      "             15       0.15           10             True               64               62       35.0       30.8           1.0\n",
      "             15       0.05           25             True                4                5       11.4       11.2           1.0\n",
      "             15       0.10           25             True               12               10       10.0        9.8           1.0\n",
      "             15       0.15           25             True                4                5        7.2        6.4           1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_transitions = [3, 7, 15]\n",
    "goal_regions = [5, 10, 25]\n",
    "goal_biases = [0.05, 0.10, 0.15]\n",
    "num_runs = 5 \n",
    "\n",
    "width, height, start, goal, obstacles = read_test_map(\"./tests/columns_small.txt\")\n",
    "results = []\n",
    "\n",
    "for max_transition in max_transitions:\n",
    "    for goal_region in goal_regions:\n",
    "        for goal_bias in goal_biases:\n",
    "            run_results = []\n",
    "            for _ in range(num_runs):\n",
    "                found, end_node, number_of_steps, tree, all_points = rrt(\n",
    "                    width, height, obstacles, *start, *goal, \n",
    "                    max_transition=max_transition, goal_bias=goal_bias, goal_region=goal_region\n",
    "                )\n",
    "                run_results.append({\"found\": found, \n",
    "                                    \"number_of_steps\": number_of_steps, \n",
    "                                    \"number_of_nodes\": len(all_points)})\n",
    "\n",
    "            first_run = run_results[0]\n",
    "\n",
    "            avg_steps = mean(run[\"number_of_steps\"] for run in run_results)\n",
    "            avg_nodes = mean(run[\"number_of_nodes\"] for run in run_results)\n",
    "            success_rate = sum(run[\"found\"] for run in run_results) / num_runs\n",
    "\n",
    "            results.append({\n",
    "                \"max_transition\": max_transition,\n",
    "                \"goal_bias\": goal_bias,\n",
    "                \"goal_region\": goal_region,\n",
    "                \"first_run_found\": first_run[\"found\"],\n",
    "                \"first_run_steps\": first_run[\"number_of_steps\"],\n",
    "                \"first_run_nodes\": first_run[\"number_of_nodes\"],\n",
    "                \"avg_steps\": avg_steps,\n",
    "                \"avg_nodes\": avg_nodes,\n",
    "                \"success_rate\": success_rate\n",
    "            })\n",
    "            line = results[-1]\n",
    "            print(\"-----------------\")\n",
    "            print(f\"Max transition: {line['max_transition']}\")\n",
    "            print(f\"Goal bias: {line['goal_bias']}\")\n",
    "            print(f\"Goal region: {line['goal_region']}\")\n",
    "            print(f\"First run - Found: {line['first_run_found']}, Steps: {line['first_run_steps']}, Nodes: {line['first_run_nodes']}\")\n",
    "            print(f\"Avg steps: {line['avg_steps']}\")\n",
    "            print(f\"Avg nodes: {line['avg_nodes']}\")\n",
    "            print(f\"Success rate: {line['success_rate']:.2f}\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
